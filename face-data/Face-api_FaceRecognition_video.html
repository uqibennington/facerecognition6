<!-- 
Author : ChungYi Fu (Kaohsiung, Taiwan)   2020/2/10 22:00
https://www.facebook.com/francefu

Try it!
https://fustyles.github.io/webduino/TensorFlow/Face-api/Face-api_FaceRecognition_video.html

How to enable WebGL in Chrome.
https://superuser.com/questions/836832/how-can-i-enable-webgl-in-my-browser

Easy Face Recognition Tutorial With JavaScript
https://www.youtube.com/watch?v=AZ4PdALMqx0
-->
<!DOCTYPE html>
<head>
  <title>Face Recognition</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src='face-api.min.js'></script>
</head>
<body>
<button onclick="location.href=location.pathname;">Front Camera</button>&nbsp;&nbsp;<button onclick="location.href='?back';">Rear Camera</button><br>
<video id="video" width="320" height="240" preload autoplay loop muted></video>
<canvas id="canvas"></canvas><br>
<button id="detect" onclick="this.disabled=true;DetectVideo();" disabled>Start Detection</button><br>
<div id="message" style="width:350px;color:red">Please wait for loading model.</div>

<script>
var video = document.getElementById('video');
var canvas = document.getElementById('canvas'); 
var detect = document.getElementById('detect'); 
var message = document.getElementById('message');
	
const distanceLimit = 0.4;
const faceImagesPath = './facelist/';   
const facelabels = ['傅仲儀', '蔡依帆'];
faceImagesCount = 2 ;
// /LabelName/n.jpg  -->  /France/1.jpg, /France/2.jpg, /Terry/1.jpg, /Terry/2.jpg
const modelPath = './';
let displaySize = { width:320, height: 240 };

let labeledFaceDescriptors;
let faceMatcher;

  function loadModel() {
    Promise.all([
      faceapi.nets.faceLandmark68Net.load(modelPath),
      faceapi.nets.faceRecognitionNet.load(modelPath),
      faceapi.nets.ssdMobilenetv1.load(modelPath)
    ]).then(function(){
      startvideo();
    })
  }
  
  function startvideo() {
	if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {
	  console.log("enumerateDevices() not supported.");
	  return;
	}

	var videoWidth = 320;
	var videoHeight = 240;
	
    var back = {audio: false,video: {facingMode: 'user',width: videoWidth,height: videoHeight}};
	navigator.mediaDevices.enumerateDevices()
		.then(function(devices) {
		  devices.forEach(function(device) {
			  if (device.kind=="videoinput"&&device.label.includes("facing back")) {
				if (device.deviceId=='')
					back = {audio: false,video: {facingMode: 'environment',width: videoWidth,height: videoHeight} };
				else
					back = {audio: false,video: {deviceId: {'exact':device.deviceId}, facingMode: 'environment',width: videoWidth,height: videoHeight} };
			  }
		  });
		
		
		if (location.search.toLowerCase().indexOf("?back")!=-1)
		  var userMedia = back;
		else
		  var userMedia = {audio: false,video: {facingMode: 'user',width: videoWidth,height: videoHeight}};

		navigator.mediaDevices
		  .getUserMedia(userMedia)
		  .then(stream => {
			video.srcObject = stream
			video.onloadedmetadata = () => {   		
			  video.play();
			  detect.disabled=false;
			  message.innerHTML = "";
			}
		 })  
	})   
  }
                        
  async function DetectVideo() { 

	  canvas.setAttribute("width", video.width);
	  canvas.setAttribute("height", video.height); 
      canvas.getContext('2d').drawImage(video,0,0,video.width,video.height); 

	  if (!labeledFaceDescriptors) {
	    video.style.display = "none";
            message.innerHTML = "Loading face images...";		  
	    labeledFaceDescriptors = await loadLabeledImages();
	    faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, distanceLimit)
	  }

      const detections = await faceapi.detectAllFaces(canvas).withFaceLandmarks().withFaceDescriptors();
      const resizedDetections = faceapi.resizeResults(detections, displaySize);

	  const results = resizedDetections.map(d => faceMatcher.findBestMatch(d.descriptor));
      message.innerHTML = JSON.stringify(results);
	  
      results.forEach((result, i) => {
		const box = resizedDetections[i].detection.box
		var drawBox;
		if (result.distance<=distanceLimit)
			drawBox = new faceapi.draw.DrawBox(box, { label: result.toString()})
		else
			drawBox = new faceapi.draw.DrawBox(box, { label: (Math.round(result.distance*100)/100).toString()})
		drawBox.draw(canvas);
      })

	  setTimeout(function(){DetectVideo(); }, 100);
  }

  function loadLabeledImages() {
	return Promise.all(
		facelabels.map(async label => {
			const descriptions = []
			for (let i=1;i<=faceImagesCount;i++) {
				const img = await faceapi.fetchImage(faceImagesPath+label+'/'+i+'.jpg')
				const detections = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor();
				descriptions.push(detections.descriptor)
			}
			return new faceapi.LabeledFaceDescriptors(label, descriptions)
		})
	)
  }

  window.onload = function () { loadModel(); }
</script>

</body>
</html>
