<!-- 
Author : ChungYi Fu (Kaohsiung, Taiwan)   2020/1/4 22:00
https://www.facebook.com/francefu

Try it!
https://fustyles.github.io/webduino/TensorFlow/Face-api/Face-api_FaceDetection_video.html

How to enable WebGL in Chrome.
https://superuser.com/questions/836832/how-can-i-enable-webgl-in-my-browser
-->
<!DOCTYPE html>
<head>
  <title>Face Detection</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src='face-api.min.js'></script>
<style>
  #webcam-container {
    padding: 0;
  }
  #hide {
    position: absolute;
    top: 250px;
    left: 0;
  }
  #message {
    position: absolute;
    top: 280px;
    left: 0;
    color:red;
  }
  canvas {
    position: absolute;
    top: 0;
    left: 0;
  }
  video {
    position: absolute;
    top: 0;
    left: 0;
  }
</style>
</head>
<body>
<video id="webcam" autoplay muted playsinline></video>
<div id="webcam-container"></div>
<div id="hide">
<button onclick="location.href=location.pathname;">Front Camera</button>&nbsp;&nbsp;<button onclick="location.href='?back';">Rear Camera</button>
<input type="checkbox" onclick="if (this.checked) camera.style.display='none'; else camera.style.display='block';" value="">Hide Video
</div>
<div id="message">Please wait for loading model.</div>
  
<script>
const camera = document.getElementById('webcam');
const modelPath = './';
let currentStream;
let displaySize = { width:320, height: 240 }
let canvas;
let faceDetection;
let message = document.getElementById('message'); 
  
  window.onload = function() {LoadModel();}
  function LoadModel() {
    Promise.all([
      faceapi.nets.tinyFaceDetector.load(modelPath),
      faceapi.nets.faceLandmark68TinyNet.load(modelPath),
      faceapi.nets.faceRecognitionNet.load(modelPath),
      faceapi.nets.faceExpressionNet.load(modelPath),
      faceapi.nets.ageGenderNet.load(modelPath)
    ]).then(function(){
      startVideo();
    })
  }  
  
  function startVideo() {
	if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {
	  console.log("enumerateDevices() not supported.");
	  return;
	}

	var videoWidth = 320;
	var videoHeight = 240;
	
    var back = {audio: false,video: {facingMode: 'user',width: videoWidth,height: videoHeight}};
	navigator.mediaDevices.enumerateDevices()
		.then(function(devices) {
		  devices.forEach(function(device) {
			  if (device.kind=="videoinput"&&device.label.includes("facing back")) {
				if (device.deviceId=='')
					back = {audio: false,video: {facingMode: 'environment',width: videoWidth,height: videoHeight} };
				else
					back = {audio: false,video: {deviceId: {'exact':device.deviceId}, facingMode: 'environment',width: videoWidth,height: videoHeight} };
			  }
		  });
		
		
		if (location.search.toLowerCase().indexOf("?back")!=-1)
		  var userMedia = back;
		else
		  var userMedia = {audio: false,video: {facingMode: 'user',width: videoWidth,height: videoHeight}};

		navigator.mediaDevices
		  .getUserMedia(userMedia)
		  .then(stream => {
			camera.srcObject = stream
			camera.onloadedmetadata = () => {       
			  camera.play();
			  if( document.getElementsByTagName("canvas").length == 0 )
			  {
				canvas = faceapi.createCanvasFromMedia(camera)
				document.getElementById('webcam-container').append(canvas)
				faceapi.matchDimensions(canvas, displaySize)
			  }  
			  //camera.style.visibility="hidden";     
			  DetectVideo();
			}
		 })  
	}) 

  }
                        
  async function DetectVideo() {
      const detections = await faceapi.detectAllFaces(camera, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks(true).withFaceExpressions().withAgeAndGender()
      const resizedDetections = faceapi.resizeResults(detections, displaySize)
      canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height)
      faceapi.draw.drawDetections(canvas, resizedDetections)
      faceapi.draw.drawFaceLandmarks(canvas, resizedDetections)
      faceapi.draw.drawFaceExpressions(canvas, resizedDetections)
      resizedDetections.forEach(result => {
        const { age, gender, genderProbability } = result
        message.innerHTML = JSON.stringify(result);
        new faceapi.draw.DrawTextField(
          [
            `${faceapi.round(age, 0)} years`,
            `${gender} (${faceapi.round(genderProbability)})`
          ],
          result.detection.box.bottomRight
        ).draw(canvas)
      })
      try { 
        document.createEvent("TouchEvent");
        setTimeout(function(){DetectVideo();},250);
      }
      catch(e) { 
        setTimeout(function(){DetectVideo();},150);
      } 
  }
</script>

</body>
</html>
